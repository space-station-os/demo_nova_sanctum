# -*- coding: utf-8 -*-
"""Machine learning methods to infer STL specification for ARS.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1jUP7F9k2DuluvNjC1WmOrGSn9w3iccM4
"""

# Check if NVIDIA GPU is enabled
!nvidia-smi

from google.colab import drive
drive.mount('/content/gdrive')

!ls /content/gdrive/MyDrive/ML_training_models

"""Got it! Here's a structured **markdown documentation** based on your code.

---

# CO2 Mass Optimization using Multiple Algorithms

## Overview
This project aims to **optimize the bounds (a and b)** for a CO2 mass dataset over time using various optimization techniques. The objective function is designed to **maximize the tightness metric** calculated from robustness values over a given time scale.

## Optimization Techniques Used

1. **L-BFGS-B**
2. **Differential Evolution**
3. **Dual Annealing**

---

## Dependencies
Make sure you have the following Python packages installed:
```bash
pip install numpy scipy matplotlib pandas
```

---

## Data Loading and Preprocessing

```python
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt

# Load the CSV file
df = pd.read_csv('/content/gdrive/MyDrive/ML_training_models/collector_air_quality.csv')

# Convert timestamp to seconds
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['time_sec'] = (df['timestamp'] - df['timestamp'].iloc[0]).dt.total_seconds()

# Extract relevant columns
timestamps = df['time_sec'].values
co2_mass = df['co2_mass'].values

# Plotting the CO2 mass signal
plt.figure(figsize=(12, 6))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')
plt.title('CO2 Mass Over Time')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()
```

---

## Robustness and Tightness Functions

### Robustness Functions

```python
def robustness_predicate(signal_value, alpha):
    return signal_value - alpha

def robustness_and(robustness1, robustness2):
    return np.minimum(robustness1, robustness2)
```

### Tightness Metric Functions

```python
def peak_function(r, beta=1):
    exponent = np.clip(-beta * r, -500, 500)
    return 1 / (r + np.exp(exponent))

def expansion_function(gamma, t1, t2):
    exponent = np.clip(-gamma * (t2 - t1 + 1), -100, 100)
    return 2 / (1 + np.exp(exponent))

def robustness_globally(robustness_values, t1, t2, gamma=1):
    base_value = np.min(robustness_values[t1:t2+1])
    scaling_factor = expansion_function(gamma, t1, t2)
    return scaling_factor * base_value
```

### Computing Robustness and Tightness

```python
def compute_robustness(timestamps, co2_mass, a, b, T):
    robustness_values = []
    end_time = min(timestamps[-1], T)
    
    for t_idx, t in enumerate(timestamps):
        if t > end_time - 400:
            break
        
        r1 = robustness_predicate(co2_mass[t_idx], a)
        r2 = robustness_predicate(b, co2_mass[t_idx])

        r3 = robustness_and(r1, r2)
        
        robustness_values.append(r3)

    return robustness_values

def compute_tightness_metric(robustness_values, T, beta=1, gamma=1):
    theta_values = np.array([peak_function(r, beta) for r in robustness_values])
    final_tightness = robustness_globally(theta_values, 0, len(theta_values)-1, gamma=gamma)
    return final_tightness
```

---

## Optimization Methods

### Objective Function

```python
from scipy.optimize import minimize, differential_evolution, dual_annealing

def tightness_objective(x, timestamps, co2_mass, T, beta=1, gamma=1):
    a, b = x
    robustness_values = compute_robustness(timestamps, co2_mass, a, b, T)
    tightness_value = compute_tightness_metric(robustness_values, T, beta, gamma)
    return -tightness_value  # Negative because we want to maximize the tightness
```

### L-BFGS-B Optimization

```python
results = {}
result_lbfgs = minimize(
    fun=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=50, gamma=10),
    x0=[15, 300],
    bounds=[(0, np.max(co2_mass) / 2), (np.max(co2_mass) / 2, np.max(co2_mass) * 2)],
    method='L-BFGS-B'
)
results['L-BFGS-B'] = result_lbfgs.x
```

### Differential Evolution

```python
result_de = differential_evolution(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    strategy='best1bin', maxiter=1000, tol=1e-7, mutation=(0.5, 1), recombination=0.7
)
results['Differential Evolution'] = result_de.x
```

### Dual Annealing

```python
result_da = dual_annealing(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    maxiter=1000, initial_temp=5230, visit=2.62, accept=-5.0
)
results['Dual Annealing'] = result_da.x
```

---

## Displaying Results as a Table

```python
import pandas as pd

df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Optimized a', 'Optimized b'])
print("Optimization Results:\n")
print(df_results)
```

---

## Plotting the Results

```python
plt.figure(figsize=(14, 7))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')

# Adding optimized lines from each method
colors = ['red', 'green', 'orange']
for (label, (a_opt, b_opt)), color in zip(results.items(), colors):
    plt.axhline(y=a_opt, color=color, linestyle='--', label=f'{label} Optimized a = {a_opt:.2f}')
    plt.axhline(y=b_opt, color=color, linestyle='--', label=f'{label} Optimized b = {b_opt:.2f}')

plt.title('CO2 Mass Over Time with Optimized Bounds')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()
```

---

## Conclusion

This approach demonstrates how to use various optimization techniques to find optimal bounds for a CO2 mass dataset. Each method has its strengths and weaknesses:

- **L-BFGS-B:** Fast and efficient for smooth, differentiable functions.
- **Differential Evolution:** Robust against multimodal and non-differentiable functions.
- **Dual Annealing:** Stochastic approach that balances global search with local refinements.



### Reference

1.TeLEx: Passive STL Learning Using Only Positive Examples by Susmit Jha1,et.al
"""

import pandas as pd
import matplotlib.pyplot as plt
import numpy as np

from scipy.optimize import minimize
from scipy.optimize import differential_evolution

# Load the CSV file
df = pd.read_csv('/content/gdrive/MyDrive/ML_training_models/collector_air_quality.csv')

# Convert timestamp to seconds
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['time_sec'] = (df['timestamp'] - df['timestamp'].iloc[0]).dt.total_seconds()

# Extract relevant columns
timestamps = df['time_sec'].values
co2_mass = df['co2_mass'].values

# Plotting the CO2 mass signal
plt.figure(figsize=(12, 6))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')
plt.title('CO2 Mass Over Time')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()

def robustness_predicate(signal_value, alpha):
    """
    Robustness for a predicate μ(x) := g(x) ≥ α
    """
    return signal_value - alpha

def robustness_negation(robustness_value):
    """
    Robustness for negation ¬φ
    """
    return -robustness_value

def robustness_or(robustness1, robustness2):
    """
    Robustness for disjunction (φ1 ∨ φ2)
    """
    return np.maximum(robustness1, robustness2)

def robustness_and(robustness1, robustness2):
    """
    Robustness for conjunction (φ1 ∧ φ2)
    """
    return np.minimum(robustness1, robustness2)

def robustness_eventually(robustness_values, t1, t2, gamma=1):
    base_value = np.max(robustness_values[t1:t2+1])
    scaling_factor = contraction_function(gamma, t1, t2)
    return scaling_factor * base_value

def robustness_globally(robustness_values, t1, t2, gamma=1):
    base_value = np.min(robustness_values[t1:t2+1])
    scaling_factor = expansion_function(gamma, t1, t2)
    return scaling_factor * base_value



# Tightness Metric Functions
def peak_function(r, beta=1):
    """
    Peak function P(r) as described in the paper.
    """
    exponent=np.clip(-beta * r, -500, 500)
    return 1/(r+np.exp(exponent))

def contraction_function(gamma, t1, t2):
    exponent = np.clip(gamma * (t2 - t1 + 1), -100, 100)
    return 2 / (1 + np.exp(exponent))

def expansion_function(gamma, t1, t2):
    exponent = np.clip(-gamma * (t2 - t1 + 1), -100, 100)
    return 2 / (1 + np.exp(exponent))

# Compute Robustness Values for Each Timestamp
def compute_robustness(timestamps, co2_mass, a, b, T):
    robustness_values = []
    end_time = min(timestamps[-1], T)

    for t_idx, t in enumerate(timestamps):
        if t > end_time - 400:
            break

        # Compute predicates for each timestamp
        r1 = robustness_predicate( a,co2_mass[t_idx],)
        r2 = robustness_predicate(b, co2_mass[t_idx])

        # Compute OR operation robustness
        r3 = robustness_and(r1, r2)

        robustness_values.append(r3)  # Store the robustness value directly

    return robustness_values





def compute_tightness_metric(robustness_values, T, beta=1, gamma=1):
    """
    Compute the overall tightness metric θ from robustness values.
    """

    # Apply Peak Function to all robustness values (Apply here, not before!)
    theta_values = np.array([peak_function(r, beta) for r in robustness_values])


    # Apply Globally operation over the interval [0, T]
    final_tightness = robustness_globally([theta_values], 0, 0, gamma=gamma)

    return final_tightness


def tightness_objective(x, timestamps, co2_mass, T, beta=1, gamma=1):
    a, b = x
    robustness_values = compute_robustness(timestamps, co2_mass, a, b, T)
    tightness_value = compute_tightness_metric(robustness_values, T, beta, gamma)
    print(f"a: {a}\n, b: {b}\n, tightness_value: {tightness_value}\n")

    return tightness_value  # Negative because we want to maximize the tightness

"""G[0, T] ( (co2_mass >= a) or (co2_mass <= b) )

"""

# Store results for each optimizer
results = {}

# L-BFGS-B Optimizer
result_lbfgs = minimize(
    fun=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=50, gamma=10),
    x0=[15, 300],
    bounds=[(0, np.max(co2_mass) / 2), (np.max(co2_mass) / 2, np.max(co2_mass) * 2)],
    method='L-BFGS-B'
)
results['L-BFGS-B'] = result_lbfgs.x

# Differential Evolution Optimizer
result_de = differential_evolution(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    strategy='best1bin', maxiter=1000, tol=1e-7, mutation=(0.5, 1), recombination=0.7
)
results['Differential Evolution'] = result_de.x

# Dual Annealing Optimizer
result_da = dual_annealing(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    maxiter=1000, initial_temp=5230, visit=2.62, accept=-5.0
)
results['Dual Annealing'] = result_da.x

# Display results as a table
import pandas as pd

df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Optimized a', 'Optimized b'])
print("Optimization Results:\n")
print(df_results)

# Plotting
plt.figure(figsize=(14, 7))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')

# Adding optimized lines from each method
colors = ['red', 'green', 'orange']
for (label, (a_opt, b_opt)), color in zip(results.items(), colors):
    plt.axhline(y=a_opt, color=color, linestyle='--', label=f'{label} Optimized a = {a_opt:.2f}')
    plt.axhline(y=b_opt, color=color, linestyle='--', label=f'{label} Optimized b = {b_opt:.2f}')

plt.title('CO2 Mass Over Time with Optimized Bounds')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()

# Load the CSV file
df = pd.read_csv('/content/gdrive/MyDrive/ML_training_models/desiccant_air_quality.csv')

# Convert timestamp to seconds
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['time_sec'] = (df['timestamp'] - df['timestamp'].iloc[0]).dt.total_seconds()

# Extract relevant columns
timestamps = df['time_sec'].values
co2_mass = df['co2_mass'].values

# Plotting the CO2 mass signal
plt.figure(figsize=(12, 6))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')
plt.title('CO2 Mass Over Time')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()

def robustness_predicate(signal_value, alpha):
    """
    Robustness for a predicate μ(x) := g(x) ≥ α
    """
    return signal_value - alpha

def robustness_negation(robustness_value):
    """
    Robustness for negation ¬φ
    """
    return -robustness_value

def robustness_or(robustness1, robustness2):
    """
    Robustness for disjunction (φ1 ∨ φ2)
    """
    return np.maximum(robustness1, robustness2)

def robustness_and(robustness1, robustness2):
    """
    Robustness for conjunction (φ1 ∧ φ2)
    """
    return np.minimum(robustness1, robustness2)

def robustness_eventually(robustness_values, t1, t2, gamma=1):
    base_value = np.max(robustness_values[t1:t2+1])
    scaling_factor = contraction_function(gamma, t1, t2)
    return scaling_factor * base_value

def robustness_globally(robustness_values, t1, t2, gamma=1):
    base_value = np.min(robustness_values[t1:t2+1])
    scaling_factor = expansion_function(gamma, t1, t2)
    return scaling_factor * base_value



# Tightness Metric Functions
def peak_function(r, beta=1):
    """
    Peak function P(r) as described in the paper.
    """
    exponent=np.clip(-beta * r, -500, 500)
    return 1/(r+np.exp(exponent))

def contraction_function(gamma, t1, t2):
    exponent = np.clip(gamma * (t2 - t1 + 1), -100, 100)
    return 2 / (1 + np.exp(exponent))

def expansion_function(gamma, t1, t2):
    exponent = np.clip(-gamma * (t2 - t1 + 1), -100, 100)
    return 2 / (1 + np.exp(exponent))

# Compute Robustness Values for Each Timestamp
def compute_robustness(timestamps, co2_mass, a, b, T):
    robustness_values = []
    end_time = min(timestamps[-1], T)

    for t_idx, t in enumerate(timestamps):
        if t > end_time - 400:
            break

        # Compute predicates for each timestamp
        r1 = robustness_predicate( a,co2_mass[t_idx],)
        r2 = robustness_predicate(b, co2_mass[t_idx])

        # Compute OR operation robustness
        r3 = robustness_and(r1, r2)

        robustness_values.append(r3)  # Store the robustness value directly

    return robustness_values





def compute_tightness_metric(robustness_values, T, beta=1, gamma=1):
    """
    Compute the overall tightness metric θ from robustness values.
    """

    # Apply Peak Function to all robustness values (Apply here, not before!)
    theta_values = np.array([peak_function(r, beta) for r in robustness_values])


    # Apply Globally operation over the interval [0, T]
    final_tightness = robustness_globally([theta_values], 0, 0, gamma=gamma)

    return final_tightness


def tightness_objective(x, timestamps, co2_mass, T, beta=1, gamma=1):
    a, b = x
    robustness_values = compute_robustness(timestamps, co2_mass, a, b, T)
    tightness_value = compute_tightness_metric(robustness_values, T, beta, gamma)
    print(f"a: {a}\n, b: {b}\n, tightness_value: {tightness_value}\n")

    return tightness_value  # Negative because we want to maximize the tightness

# Store results for each optimizer
results = {}

# L-BFGS-B Optimizer
result_lbfgs = minimize(
    fun=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=50, gamma=10),
    x0=[15, 300],
    bounds=[(0, np.max(co2_mass) / 2), (np.max(co2_mass) / 2, np.max(co2_mass) * 2)],
    method='L-BFGS-B'
)
results['L-BFGS-B'] = result_lbfgs.x

# Differential Evolution Optimizer
result_de = differential_evolution(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    strategy='best1bin', maxiter=1000, tol=1e-7, mutation=(0.5, 1), recombination=0.7
)
results['Differential Evolution'] = result_de.x

# Dual Annealing Optimizer
result_da = dual_annealing(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    maxiter=1000, initial_temp=5230, visit=2.62, accept=-5.0
)
results['Dual Annealing'] = result_da.x

# Display results as a table
import pandas as pd

df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Optimized a', 'Optimized b'])
print("Optimization Results:\n")
print(df_results)

# Plotting
plt.figure(figsize=(14, 7))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')

# Adding optimized lines from each method
colors = ['red', 'green', 'orange']
for (label, (a_opt, b_opt)), color in zip(results.items(), colors):
    plt.axhline(y=a_opt, color=color, linestyle='--', label=f'{label} Optimized a = {a_opt:.2f}')
    plt.axhline(y=b_opt, color=color, linestyle='--', label=f'{label} Optimized b = {b_opt:.2f}')

plt.title('CO2 Mass Over Time with Optimized Bounds')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()

# Load the CSV file
df = pd.read_csv('/content/gdrive/MyDrive/ML_training_models/adsorbent_air_quality.csv')

# Convert timestamp to seconds
df['timestamp'] = pd.to_datetime(df['timestamp'])
df['time_sec'] = (df['timestamp'] - df['timestamp'].iloc[0]).dt.total_seconds()

# Extract relevant columns
timestamps = df['time_sec'].values
co2_mass = df['co2_mass'].values

# Plotting the CO2 mass signal
plt.figure(figsize=(12, 6))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')
plt.title('CO2 Mass Over Time')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()

def robustness_predicate(signal_value, alpha):
    """
    Robustness for a predicate μ(x) := g(x) ≥ α
    """
    return signal_value - alpha

def robustness_negation(robustness_value):
    """
    Robustness for negation ¬φ
    """
    return -robustness_value

def robustness_or(robustness1, robustness2):
    """
    Robustness for disjunction (φ1 ∨ φ2)
    """
    return np.maximum(robustness1, robustness2)

def robustness_and(robustness1, robustness2):
    """
    Robustness for conjunction (φ1 ∧ φ2)
    """
    return np.minimum(robustness1, robustness2)

def robustness_eventually(robustness_values, t1, t2, gamma=1):
    base_value = np.max(robustness_values[t1:t2+1])
    scaling_factor = contraction_function(gamma, t1, t2)
    return scaling_factor * base_value

def robustness_globally(robustness_values, t1, t2, gamma=1):
    base_value = np.min(robustness_values[t1:t2+1])
    scaling_factor = expansion_function(gamma, t1, t2)
    return scaling_factor * base_value



# Tightness Metric Functions
def peak_function(r, beta=1):
    """
    Peak function P(r) as described in the paper.
    """
    exponent=np.clip(-beta * r, -500, 500)
    return 1/(r+np.exp(exponent))

def contraction_function(gamma, t1, t2):
    exponent = np.clip(gamma * (t2 - t1 + 1), -100, 100)
    return 2 / (1 + np.exp(exponent))

def expansion_function(gamma, t1, t2):
    exponent = np.clip(-gamma * (t2 - t1 + 1), -100, 100)
    return 2 / (1 + np.exp(exponent))

# Compute Robustness Values for Each Timestamp
def compute_robustness(timestamps, co2_mass, a, b, T):
    robustness_values = []
    end_time = min(timestamps[-1], T)

    for t_idx, t in enumerate(timestamps):
        if t > end_time - 400:
            break

        # Compute predicates for each timestamp
        r1 = robustness_predicate( a,co2_mass[t_idx],)
        r2 = robustness_predicate(b, co2_mass[t_idx])

        # Compute OR operation robustness
        r3 = robustness_and(r1, r2)

        robustness_values.append(r3)  # Store the robustness value directly

    return robustness_values





def compute_tightness_metric(robustness_values, T, beta=1, gamma=1):
    """
    Compute the overall tightness metric θ from robustness values.
    """

    # Apply Peak Function to all robustness values (Apply here, not before!)
    theta_values = np.array([peak_function(r, beta) for r in robustness_values])


    # Apply Globally operation over the interval [0, T]
    final_tightness = robustness_globally([theta_values], 0, 0, gamma=gamma)

    return final_tightness


def tightness_objective(x, timestamps, co2_mass, T, beta=1, gamma=1):
    a, b = x
    robustness_values = compute_robustness(timestamps, co2_mass, a, b, T)
    tightness_value = compute_tightness_metric(robustness_values, T, beta, gamma)
    print(f"a: {a}\n, b: {b}\n, tightness_value: {tightness_value}\n")

    return tightness_value  # Negative because we want to maximize the tightness

# Store results for each optimizer
results = {}

# L-BFGS-B Optimizer
result_lbfgs = minimize(
    fun=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=50, gamma=10),
    x0=[15, 300],
    bounds=[(0, np.max(co2_mass) / 2), (np.max(co2_mass) / 2, np.max(co2_mass) * 2)],
    method='L-BFGS-B'
)
results['L-BFGS-B'] = result_lbfgs.x

# Differential Evolution Optimizer
result_de = differential_evolution(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    strategy='best1bin', maxiter=1000, tol=1e-7, mutation=(0.5, 1), recombination=0.7
)
results['Differential Evolution'] = result_de.x

# Dual Annealing Optimizer
result_da = dual_annealing(
    func=lambda x: tightness_objective(x, timestamps, co2_mass, timestamps[-1], beta=1.5, gamma=0.5),
    bounds=[(0, np.percentile(co2_mass, 20)), (np.percentile(co2_mass, 80), np.max(co2_mass))],
    maxiter=1000, initial_temp=5230, visit=2.62, accept=-5.0
)
results['Dual Annealing'] = result_da.x

# Display results as a table
import pandas as pd

df_results = pd.DataFrame.from_dict(results, orient='index', columns=['Optimized a', 'Optimized b'])
print("Optimization Results:\n")
print(df_results)

# Plotting
plt.figure(figsize=(14, 7))
plt.plot(timestamps, co2_mass, label='CO2 Mass', color='blue')

# Adding optimized lines from each method
colors = ['red', 'green', 'orange']
for (label, (a_opt, b_opt)), color in zip(results.items(), colors):
    plt.axhline(y=a_opt, color=color, linestyle='--', label=f'{label} Optimized a = {a_opt:.2f}')
    plt.axhline(y=b_opt, color=color, linestyle='--', label=f'{label} Optimized b = {b_opt:.2f}')

plt.title('CO2 Mass Over Time with Optimized Bounds')
plt.xlabel('Timestamp (seconds)')
plt.ylabel('CO2 Mass (kg)')
plt.legend()
plt.grid(True)
plt.show()

